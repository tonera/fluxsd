<?php
return [
    'together' => [
        'config' => [
            [
                'label' => 'Output Length', 'key' => 'max_tokens', 'min' => 1, 'max' => 131072, 'def'=> 512,'step'=> 1,'type'=>'slider'
            ],
            [
                'label' => 'Temperature', 'key' => 'temperature', 'min' => 0, 'max' => 2,'def'=> 0.7,'step'=> 0.01,'type'=>'slider'
            ],
            [
                'label' => 'Top-P', 'key' => 'top_p', 'min' => 0, 'max' => 1,'def'=> 0.7,'step'=> 0.01,'type'=>'slider'
            ],
            [
                'label' => 'Top-K', 'key' => 'top_k', 'min' => 1, 'max' => 100,'def'=> 50,'step'=> 1,'type'=>'slider'
            ],
            [
                'label' => 'Repetition Penalty', 'key' => 'repetition_penalty', 'min' => 1, 'max' => 2,'def'=> 1,'step'=> 0.1,'type'=>'slider'
            ],
            [
                'label' => 'has_context', 'key' => 'has_context', 'def'=> false, 'type'=>'switch'
            ],
        ],
        'models' => [
            "meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo",
            "meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo",
            "meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo",
            "meta-llama/Meta-Llama-3.1-70B-Instruct-Reference",
            "meta-llama/Meta-Llama-3.1-70B-Reference",
            "meta-llama/Meta-Llama-Guard-3-8B",
            "meta-llama/Meta-Llama-3.1-8B-Reference",
            "meta-llama/Meta-Llama-3-70B-Instruct-Turbo",
            "google/gemma-2-9b",
            "meta-llama/Meta-Llama-3-70B-Instruct-Lite",
            "meta-llama/Meta-Llama-3.1-8B-Instruct-Reference",
            "meta-llama/Meta-Llama-3-8B-Instruct-Lite",
            "meta-llama/Meta-Llama-3-8B-Instruct-Turbo",
            "meta-llama/Llama-3-70b-chat-hf",
            "meta-llama/Llama-3-8b-chat-hf",
            "Qwen/Qwen2-72B-Instruct",
            "google/gemma-2-27b-it",
            "google/gemma-2-9b-it",
            "NousResearch/Hermes-2-Theta-Llama-3-70B",
            "gradientai/Llama-3-70B-Instruct-Gradient-1048k",
            "medaltv/dbrx-instruct",
            "meta-llama/Llama-3-70b-hf",
            "meta-llama/Meta-Llama-3-8B",
            "mistralai/Mistral-7B-Instruct-v0.3",
            "meta-llama/Meta-Llama-3-8B-Instruct",
            "meta-llama/Meta-Llama-3-70B-Instruct",
            "Qwen/Qwen1.5-110B-Chat",
            "Snowflake/snowflake-arctic-instruct",
            "meta-llama/Meta-Llama-3-70B",
            "meta-llama/Llama-3-8b-hf",
            "mistralai/Mixtral-8x22B-Instruct-v0.1",
            "togethercomputer/SOLAR-10.7B-Instruct-v1.0-int4",
            "meta-llama/LlamaGuard-2-8b",
            "mistralai/Mixtral-8x22B",
            "microsoft/WizardLM-2-8x22B",
            "togethercomputer/StripedHyena-Nous-7B",
            "databricks/dbrx-instruct",
            "togethercomputer/evo-1-131k-base",
            "togethercomputer/evo-1-8k-base",
            "allenai/OLMo-7B-Twin-2T",
            "allenai/OLMo-7B-Instruct",
            "allenai/OLMo-7B",
            "deepseek-ai/deepseek-llm-67b-chat",
            "google/gemma-7b-it",
            "google/gemma-2b-it",
            "google/gemma-7b",
            "google/gemma-2b",
            "NousResearch/Nous-Hermes-2-Mistral-7B-DPO",
            "mistralai/Mistral-7B-Instruct-v0.2",
            "mistralai/Mixtral-8x7B-Instruct-v0.1",
            "mistralai/Mixtral-8x7B-v0.1",
            "NousResearch/Nous-Hermes-2-Mixtral-8x7B-SFT",
            "cognitivecomputations/dolphin-2.5-mixtral-8x7b",
            "microsoft/phi-2",
            "hazyresearch/M2-BERT-2k-Retrieval-Encoder-V1",
            "Qwen/Qwen1.5-72B-Chat",
            "Qwen/Qwen1.5-72B",
            "Qwen/Qwen1.5-32B-Chat",
            "Qwen/Qwen1.5-32B",
            "Qwen/Qwen1.5-14B-Chat",
            "Qwen/Qwen1.5-14B",
            "Qwen/Qwen1.5-7B-Chat",
            "Qwen/Qwen1.5-7B",
            "Qwen/Qwen1.5-4B-Chat",
            "Qwen/Qwen1.5-4B",
            "Qwen/Qwen1.5-1.8B-Chat",
            "Qwen/Qwen1.5-1.8B",
            "Qwen/Qwen1.5-0.5B-Chat",
            "Qwen/Qwen1.5-0.5B",
            "NousResearch/Nous-Hermes-2-Yi-34B",
            "codellama/CodeLlama-70b-Instruct-hf",
            "codellama/CodeLlama-70b-Python-hf",
            "codellama/CodeLlama-70b-hf",
            "Meta-Llama/Llama-Guard-7b",
            "NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO",
            "snorkelai/Snorkel-Mistral-PairRM-DPO",
            "deepseek-ai/deepseek-coder-33b-instruct",
            "togethercomputer/StripedHyena-Hessian-7B",
            "mistralai/Mistral-7B-Instruct-v0.1",
            "mistralai/Mistral-7B-v0.1",
            "zero-one-ai/Yi-34B-Chat",
            "NousResearch/Nous-Hermes-Llama2-70b",
            "NousResearch/Nous-Hermes-Llama2-13b",
            "NousResearch/Nous-Hermes-llama-2-7b",
            "togethercomputer/Llama-2-7B-32K-Instruct",
            "togethercomputer/LLaMA-2-7B-32K",
            "meta-llama/Llama-2-70b-chat-hf",
            "meta-llama/Llama-2-13b-chat-hf",
            "meta-llama/Llama-2-7b-chat-hf",
            "meta-llama/Llama-2-70b-hf",
            "meta-llama/Llama-2-13b-hf",
            "meta-llama/Llama-2-7b-hf",
            "openchat/openchat-3.5-1210",
            "HuggingFaceH4/zephyr-7b-beta",
            "codellama/CodeLlama-13b-Instruct-hf",
            "codellama/CodeLlama-13b-Python-hf",
            "codellama/CodeLlama-13b-hf",
            "codellama/CodeLlama-34b-Instruct-hf",
            "codellama/CodeLlama-34b-Python-hf",
            "codellama/CodeLlama-34b-hf",
            "codellama/CodeLlama-7b-Instruct-hf",
            "codellama/CodeLlama-7b-Python-hf",
            "codellama/CodeLlama-7b-hf",
            "zero-one-ai/Yi-34B",
            "zero-one-ai/Yi-6B",
            "Nexusflow/NexusRaven-V2-13B",
            "NousResearch/Nous-Capybara-7B-V1p9",
            "teknium/OpenHermes-2p5-Mistral-7B",
            "upstage/SOLAR-10.7B-Instruct-v1.0",
            "togethercomputer/llama-2-70b-chat",
            "togethercomputer/llama-2-13b-chat",
            "togethercomputer/llama-2-7b-chat",
            "Undi95/Toppy-M-7B",
            "togethercomputer/m2-bert-80M-32k-retrieval",
            "togethercomputer/m2-bert-80M-8k-retrieval",
            "togethercomputer/m2-bert-80M-2k-retrieval",
            "WhereIsAI/UAE-Large-V1",
            "BAAI/bge-large-en-v1.5",
            "BAAI/bge-base-en-v1.5",
            "sentence-transformers/msmarco-bert-base-dot-v5",
            "bert-base-uncased",
            "Open-Orca/Mistral-7B-OpenOrca",
            "teknium/OpenHermes-2-Mistral-7B",
            "WizardLM/WizardLM-13B-V1.2",
            "WizardLM/WizardCoder-Python-34B-V1.0",
            "togethercomputer/CodeLlama-34b-Instruct",
            "togethercomputer/CodeLlama-34b-Python",
            "Undi95/ReMM-SLERP-L2-13B",
            "stabilityai/stable-diffusion-xl-base-1.0",
            "stabilityai/stable-diffusion-2-1",
            "SG161222/Realistic_Vision_V3.0_VAE",
            "EleutherAI/llemma_7b",
            "lmsys/vicuna-13b-v1.5-16k",
            "lmsys/vicuna-13b-v1.5",
            "lmsys/vicuna-7b-v1.5",
            "Phind/Phind-CodeLlama-34B-Python-v1",
            "Phind/Phind-CodeLlama-34B-v2",
            "togethercomputer/CodeLlama-13b-Instruct",
            "togethercomputer/CodeLlama-7b-Instruct",
            "togethercomputer/CodeLlama-13b-Python",
            "togethercomputer/CodeLlama-7b-Python",
            "togethercomputer/CodeLlama-34b",
            "togethercomputer/llama-2-70b",
            "togethercomputer/llama-2-13b",
            "togethercomputer/llama-2-7b",
            "Austism/chronos-hermes-13b",
            "NousResearch/Nous-Hermes-13b",
            "NumbersStation/nsql-llama-2-7B",
            "garage-bAInd/Platypus2-70B-instruct",
            "WizardLM/WizardLM-70B-V1.0",
            "Gryphe/MythoMax-L2-13b",
            "runwayml/stable-diffusion-v1-5",
            "huggyllama/llama-65b",
            "huggyllama/llama-30b",
            "huggyllama/llama-13b",
            "huggyllama/llama-7b",
            "prompthero/openjourney",
            "togethercomputer/Koala-13B",
            "togethercomputer/alpaca-7b",
            "wavymulder/Analog-Diffusion",
            "togethercomputer/guanaco-65b",
            "togethercomputer/guanaco-33b",
            "togethercomputer/guanaco-13b",
            "togethercomputer/guanaco-7b",
            "lmsys/vicuna-13b-v1.3",
            "togethercomputer/Koala-7B",
            "lmsys/vicuna-7b-v1.3",
        ]
    ],
    'qianwen' => [
        'config' => [
            [
                'label' => 'has_context', 'key' => 'has_context', 'def'=> false, 'type'=>'switch'
            ],
        ],
        'models' => [
            "qwen-turbo",
            'qwen-long',
            'qwen-plus',
            'qwen-max',
            'qwen-max-longcontext',
            'qwen-vl-plus',
            'qwen-vl-max',
            'qwen2-57b-a14b-instruct',
            'qwen2-72b-instruct',
            'qwen2-7b-instruct',
            'qwen2-1.5b-instruct',
            'qwen2-0.5b-instruct',
            'qwen1.5-110b-chat',
            'qwen1.5-72b-chat',
            'qwen1.5-32b-chat',
            'qwen1.5-14b-chat',
            'qwen1.5-7b-chat',
            'qwen1.5-1.8b-chat',
            'qwen1.5-0.5b-chat',
            'codeqwen1.5-7b-chat',
            'qwen-72b-chat',
            'qwen-14b-chat',
            'qwen-7b-chat',
            'qwen-1.8b-longcontext-chat',
            'qwen-1.8b-chat',
            'llama3.1-8b-instruct',
            'llama3.1-70b-instruct',
            'llama3.1-405b-instruct',
        ]
    ]
];